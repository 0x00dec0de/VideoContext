{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///webpack/bootstrap ea94504931aed4c0dd1b","webpack:///./src/videocontext.js"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,O;ACVA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,uBAAe;AACf;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA,SAAQ,kBAAkB;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAC;AACD;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAe,OAAO;AACtB,gBAAe,SAAS;AACxB,gBAAe,OAAO;AACtB;AACA;AACA;AACA,6DAA4D,6DAA6D;AACzH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAkC;AAClC;AACA;AACA;;AAEA;AACA;AACA,gBAAe,OAAO;AACtB,gBAAe,SAAS;AACxB,gBAAe,OAAO;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,UAAS;AACT;;AAEA;AACA;AACA,gBAAe,SAAS;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAe,OAAO;AACtB,gBAAe,SAAS;AACxB;AACA;AACA;AACA;AACA,mDAAkD,iCAAiC;AACnF,kDAAiD,0BAA0B;AAC3E,iDAAgD,+BAA+B;AAC/E;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,gBAAe,SAAS;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,wCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAgB,YAAY;AAC5B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAgB,OAAO;AACvB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,gBAAe,OAAO;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,wBAAuB,8BAA8B;AACrD;AACA;AACA,wBAAuB,kCAAkC;AACzD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,iBAAgB,OAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA6B,8BAA8B,OAAO;AAClE;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAgB,OAAO;AACvB;AACA;AACA;AACA;AACA,kCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,kCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA,wBAAuB,8BAA8B;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,iBAAgB,gBAAgB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,gBAAe,OAAO;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAkB;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,iBAAgB,OAAO;AACvB;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAe,OAAO;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,iBAAgB,OAAO;AACvB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA4B;AAC5B;AACA,8BAA6B,aAAa,QAAQ;AAClD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,gBAAe,aAAa;AAC5B,uBAAsB,OAAO;AAC7B,sBAAqB,OAAO;AAC5B,iCAAgC,OAAO;AACvC,iBAAgB,UAAU;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA6E;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,8EAA6E;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,8FAA6F;AAC7F;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAe,aAAa;AAC5B,gBAAe,OAAO;AACtB,gBAAe,OAAO;AACtB,iBAAgB,UAAU;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA2D;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,8FAA6F;AAC7F;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAe,OAAO;AACtB,iBAAgB,WAAW;AAC3B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAe,OAAO;AACtB,iBAAgB,WAAW;AAC3B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAe,OAAO;AACtB;AACA,iBAAgB,gBAAgB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAAyC;AACzC,0CAAyC;AACzC,wCAAuC;AACvC,6BAA4B;AAC5B,+EAA8E;AAC9E,4CAA2C;AAC3C,iBAAgB;AAChB;AACA,wCAAuC;AACvC,0CAAyC;AACzC,gCAA+B;AAC/B,wCAAuC;AACvC,yCAAwC;AACxC,4BAA2B;AAC3B,gEAA+D;AAC/D,yCAAwC;AACxC,iBAAgB;AAChB;AACA,qBAAoB,0BAA0B;AAC9C,aAAY;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAe,OAAO;AACtB,iBAAgB,eAAe;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAwC;AACxC,yCAAwC;AACxC,uCAAsC;AACtC,4BAA2B;AAC3B,yFAAwF;AACxF,2CAA0C;AAC1C,iBAAgB;AAChB;AACA,wCAAuC;AACvC,4CAA2C;AAC3C,4CAA2C;AAC3C,kCAAiC;AACjC,wCAAuC;AACvC,oCAAmC;AACnC,4BAA2B;AAC3B,oEAAmE;AACnE,oEAAmE;AACnE,sCAAqC;AACrC,sCAAqC;AACrC,sCAAqC;AACrC,sCAAqC;AACrC,8CAA6C;AAC7C,8CAA6C;AAC7C,8CAA6C;AAC7C,8CAA6C;AAC7C,qDAAoD;AACpD,iBAAgB;AAChB;AACA,uBAAsB,0BAA0B;AAChD,aAAY;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,wBAAuB,8BAA8B;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,gBAAe,OAAO;AACtB;AACA;AACA;AACA,8DAA6D,sBAAsB;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,UAAS;;AAET;AACA;AACA,UAAS;;AAET;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,kBAAiB;AACjB;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,kBAAiB;;AAEjB;AACA;AACA;AACA;AACA,sBAAqB;AACrB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,oCAAmC,8BAA8B;AACjE;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,4BAA2B,8BAA8B;AACzD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAiB;AACjB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAiB;AACjB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA","file":"videocontext.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"VideoContext\"] = factory();\n\telse\n\t\troot[\"VideoContext\"] = factory();\n})(this, function() {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId])\n \t\t\treturn installedModules[moduleId].exports;\n\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\texports: {},\n \t\t\tid: moduleId,\n \t\t\tloaded: false\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.loaded = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(0);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap ea94504931aed4c0dd1b","//Matthew Shotton, R&D User Experience,Â© BBC 2015\nimport VideoNode from \"./SourceNodes/videonode.js\";\nimport AudioNode from \"./SourceNodes/audionode.js\";\nimport ImageNode from \"./SourceNodes/imagenode.js\";\nimport CanvasNode from \"./SourceNodes/canvasnode.js\";\nimport { SOURCENODESTATE } from \"./SourceNodes/sourcenode.js\";\nimport CompositingNode from \"./ProcessingNodes/compositingnode.js\";\nimport DestinationNode from \"./DestinationNode/destinationnode.js\";\nimport EffectNode from \"./ProcessingNodes/effectnode.js\";\nimport TransitionNode from \"./ProcessingNodes/transitionnode.js\";\nimport RenderGraph from \"./rendergraph.js\";\nimport VideoElementCache from \"./videoelementcache.js\";\nimport {\n    createSigmaGraphDataFromRenderGraph,\n    visualiseVideoContextTimeline,\n    visualiseVideoContextGraph,\n    createControlFormForNode,\n    UpdateablesManager,\n    exportToJSON,\n    importSimpleEDL,\n    snapshot,\n    generateRandomId\n} from \"./utils.js\";\nimport DEFINITIONS from \"./Definitions/definitions.js\";\n\nlet updateablesManager = new UpdateablesManager();\n\n/**\n * VideoContext.\n * @module VideoContext\n */\nexport default class VideoContext {\n    /**\n     * Initialise the VideoContext and render to the specific canvas. A 2nd parameter can be passed to the constructor which is a function that get's called if the VideoContext fails to initialise.\n     *\n     * @param {Canvas} canvas - the canvas element to render the output to.\n     * @param {function} initErrorCallback - a callback for if initialising the canvas failed.\n     * @param {Object} options - a nuber of custom options which can be set on the VideoContext, generally best left as default.\n     *\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement, function(){console.error(\"Sorry, your browser dosen\\'t support WebGL\");});\n     * var videoNode = ctx.video(\"video.mp4\");\n     * videoNode.connect(ctx.destination);\n     * videoNode.start(0);\n     * videoNode.stop(10);\n     * ctx.play();\n     *\n     */\n    constructor(\n        canvas,\n        initErrorCallback,\n        options = {\n            preserveDrawingBuffer: true,\n            manualUpdate: false,\n            endOnLastSourceEnd: true,\n            useVideoElementCache: true,\n            videoElementCacheSize: 6,\n            webglContextAttributes: {\n                preserveDrawingBuffer: true,\n                alpha: false\n            }\n        }\n    ) {\n        this._canvas = canvas;\n        let manualUpdate = false;\n        this.endOnLastSourceEnd = true;\n        let webglContextAttributes = {\n            preserveDrawingBuffer: true,\n            alpha: false\n        };\n\n        if (\"manualUpdate\" in options) manualUpdate = options.manualUpdate;\n        if (\"endOnLastSourceEnd\" in options) this._endOnLastSourceEnd = options.endOnLastSourceEnd;\n        if (\"webglContextAttributes\" in options)\n            webglContextAttributes = options.webglContextAttributes;\n\n        if (webglContextAttributes.alpha === undefined) webglContextAttributes.alpha = false;\n        if (webglContextAttributes.alpha === true) {\n            console.error(\"webglContextAttributes.alpha must be false for correct opeation\");\n        }\n\n        this._gl = canvas.getContext(\"experimental-webgl\", webglContextAttributes);\n        if (this._gl === null) {\n            console.error(\"Failed to intialise WebGL.\");\n            if (initErrorCallback) initErrorCallback();\n            return;\n        }\n\n        // Initialise the video element cache\n        if (options.useVideoElementCache === undefined) options.useVideoElementCache = true;\n        this._useVideoElementCache = options.useVideoElementCache;\n        if (this._useVideoElementCache) {\n            if (!options.videoElementCacheSize) options.videoElementCacheSize = 5;\n            this._videoElementCache = new VideoElementCache(options.videoElementCacheSize);\n        }\n\n        // Create a unique ID for this VideoContext which can be used in the debugger.\n        if (this._canvas.id) {\n            if (typeof this._canvas.id === \"string\" || this._canvas.id instanceof String) {\n                this._id = canvas.id;\n            }\n        }\n        if (this._id === undefined) this._id = generateRandomId();\n        if (window.__VIDEOCONTEXT_REFS__ === undefined) window.__VIDEOCONTEXT_REFS__ = {};\n        window.__VIDEOCONTEXT_REFS__[this._id] = this;\n\n        this._renderGraph = new RenderGraph();\n        this._sourceNodes = [];\n        this._processingNodes = [];\n        this._timeline = [];\n        this._currentTime = 0;\n        this._state = VideoContext.STATE.PAUSED;\n        this._playbackRate = 1.0;\n        this._volume = 1.0;\n        this._sourcesPlaying = undefined;\n        this._destinationNode = new DestinationNode(this._gl, this._renderGraph);\n\n        this._callbacks = new Map();\n        this._callbacks.set(\"stalled\", []);\n        this._callbacks.set(\"update\", []);\n        this._callbacks.set(\"ended\", []);\n        this._callbacks.set(\"content\", []);\n        this._callbacks.set(\"nocontent\", []);\n\n        this._timelineCallbacks = [];\n\n        if (!manualUpdate) {\n            updateablesManager.register(this);\n        }\n    }\n\n    /**\n     * Reurns an ID assigned to the VideoContext instance. This will either be the same id as the underlying canvas element,\n     * or a uniquley generated one.\n     */\n    get id() {\n        return this._id;\n    }\n\n    /**\n     * Set the ID of the VideoContext instance. This should be unique.\n     */\n    set id(newID) {\n        delete window.__VIDEOCONTEXT_REFS__[this._id];\n        if (window.__VIDEOCONTEXT_REFS__[newID] !== undefined)\n            console.warn(\"Warning; setting id to that of an existing VideoContext instance.\");\n        window.__VIDEOCONTEXT_REFS__[newID] = this;\n        this._id = newID;\n    }\n\n    /**\n     * Register a callback to happen at a specific point in time.\n     * @param {number} time - the time at which to trigger the callback.\n     * @param {Function} func - the callback to register.\n     * @param {number} ordering - the order in which to call the callback if more than one is registered for the same time.\n     */\n    registerTimelineCallback(time, func, ordering = 0) {\n        this._timelineCallbacks.push({\n            time: time,\n            func: func,\n            ordering: ordering\n        });\n    }\n\n    /**\n     * Unregister a callback which happens at a specific point in time.\n     * @param {Function} func - the callback to unregister.\n     */\n    unregisterTimelineCallback(func) {\n        let toRemove = [];\n        for (let callback of this._timelineCallbacks) {\n            if (callback.func === func) {\n                toRemove.push(callback);\n            }\n        }\n        for (let callback of toRemove) {\n            let index = this._timelineCallbacks.indexOf(callback);\n            this._timelineCallbacks.splice(index, 1);\n        }\n    }\n\n    /**\n     * Regsiter a callback to listen to one of the following events: \"stalled\", \"update\", \"ended\", \"content\", \"nocontent\"\n     *\n     * \"stalled\" happend anytime playback is stopped due to unavailbale data for playing assets (i.e video still loading)\n     * . \"update\" is called any time a frame is rendered to the screen. \"ended\" is called once plackback has finished\n     * (i.e ctx.currentTime == ctx.duration). \"content\" is called a the start of a time region where there is content\n     * playing out of one or more sourceNodes. \"nocontent\" is called at the start of any time region where the\n     * VideoContext is still playing, but there are currently no activly playing soureces.\n     *\n     * @param {String} type - the event to register against (\"stalled\", \"update\", or \"ended\").\n     * @param {Function} func - the callback to register.\n     *\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement);\n     * ctx.registerCallback(\"stalled\", function(){console.log(\"Playback stalled\");});\n     * ctx.registerCallback(\"update\", function(){console.log(\"new frame\");});\n     * ctx.registerCallback(\"ended\", function(){console.log(\"Playback ended\");});\n     */\n    registerCallback(type, func) {\n        if (!this._callbacks.has(type)) return false;\n        this._callbacks.get(type).push(func);\n    }\n\n    /**\n     * Remove a previously registed callback\n     *\n     * @param {Function} func - the callback to remove.\n     *\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement);\n     *\n     * //the callback\n     * var updateCallback = function(){console.log(\"new frame\")};\n     *\n     * //register the callback\n     * ctx.registerCallback(\"update\", updateCallback);\n     * //then unregister it\n     * ctx.unregisterCallback(updateCallback);\n     *\n     */\n    unregisterCallback(func) {\n        for (let funcArray of this._callbacks.values()) {\n            let index = funcArray.indexOf(func);\n            if (index !== -1) {\n                funcArray.splice(index, 1);\n                return true;\n            }\n        }\n        return false;\n    }\n\n    _callCallbacks(type) {\n        let funcArray = this._callbacks.get(type);\n        for (let func of funcArray) {\n            func(this._currentTime);\n        }\n    }\n\n    /**\n     * Get the canvas that the VideoContext is using.\n     *\n     * @return {HTMLElement} The canvas that the VideoContext is using.\n     *\n     */\n    get element() {\n        return this._canvas;\n    }\n\n    /**\n     * Get the current state.\n     *\n     * This will be either\n     *  - VideoContext.STATE.PLAYING: current sources on timeline are active\n     *  - VideoContext.STATE.PAUSED: all sources are paused\n     *  - VideoContext.STATE.STALLED: one or more sources is unable to play\n     *  - VideoContext.STATE.ENDED: all sources have finished playing\n     *  - VideoContext.STATE.BROKEN: the render graph is in a broken state\n     * @return {number} The number representing the state.\n     *\n     */\n    get state() {\n        return this._state;\n    }\n\n    /**\n     * Set the progress through the internal timeline.\n     * Setting this can be used as a way to implement a scrubaable timeline.\n     *\n     * @param {number} currentTime - this is the currentTime to set the context to.\n     *\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement);\n     * var videoNode = ctx.video(\"video.mp4\");\n     * videoNode.connect(ctx.destination);\n     * videoNode.start(0);\n     * videoNode.stop(20);\n     * ctx.currentTime = 10; // seek 10 seconds in\n     * ctx.play();\n     *\n     */\n    set currentTime(currentTime) {\n        if (currentTime < this.duration && this._state === VideoContext.STATE.ENDED)\n            this._state = VideoContext.STATE.PAUSED;\n\n        if (typeof currentTime === \"string\" || currentTime instanceof String) {\n            currentTime = parseFloat(currentTime);\n        }\n\n        for (let i = 0; i < this._sourceNodes.length; i++) {\n            this._sourceNodes[i]._seek(currentTime);\n        }\n        for (let i = 0; i < this._processingNodes.length; i++) {\n            this._processingNodes[i]._seek(currentTime);\n        }\n        this._currentTime = currentTime;\n    }\n\n    /**\n     * Get how far through the internal timeline has been played.\n     *\n     * Getting this value will give the current playhead position. Can be used for updating timelines.\n     * @return {number} The time in seconds through the current playlist.\n     *\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement);\n     * var videoNode = ctx.video(\"video.mp4\");\n     * videoNode.connect(ctx.destination);\n     * videoNode.start(0);\n     * videoNode.stop(10);\n     * ctx.play();\n     * setTimeout(function(){console.log(ctx.currentTime);},1000); //should print roughly 1.0\n     *\n     */\n    get currentTime() {\n        return this._currentTime;\n    }\n\n    /**\n     * Get the time at which the last node in the current internal timeline finishes playing.\n     *\n     * @return {number} The end time in seconds of the last video node to finish playing.\n     *\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement);\n     * console.log(ctx.duration); //prints 0\n     *\n     * var videoNode = ctx.video(\"video.mp4\");\n     * videoNode.connect(ctx.destination);\n     * videoNode.start(0);\n     * videoNode.stop(10);\n     *\n     * console.log(ctx.duration); //prints 10\n     *\n     * ctx.play();\n     */\n    get duration() {\n        let maxTime = 0;\n        for (let i = 0; i < this._sourceNodes.length; i++) {\n            if (\n                this._sourceNodes[i].state !== SOURCENODESTATE.waiting &&\n                this._sourceNodes[i]._stopTime > maxTime\n            ) {\n                maxTime = this._sourceNodes[i]._stopTime;\n            }\n        }\n        return maxTime;\n    }\n\n    /**\n     * Get the final node in the render graph which represents the canvas to display content on to.\n     *\n     * This proprety is read-only and there can only ever be one destination node. Other nodes can connect to this but you cannot connect this node to anything.\n     *\n     * @return {DestinationNode} A graph node represnting the canvas to display the content on.\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement);\n     * var videoNode = ctx.video(\"video.mp4\");\n     * videoNode.start(0);\n     * videoNode.stop(10);\n     * videoNode.connect(ctx.destination);\n     *\n     */\n    get destination() {\n        return this._destinationNode;\n    }\n\n    /**\n     * Set the playback rate of the VideoContext instance.\n     * This will alter the playback speed of all media elements played through the VideoContext.\n     *\n     * @param {number} rate - this is the playback rate.\n     *\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement);\n     * var videoNode = ctx.video(\"video.mp4\");\n     * videoNode.start(0);\n     * videoNode.stop(10);\n     * videoNode.connect(ctx.destination);\n     * ctx.playbackRate = 2;\n     * ctx.play(); // Double playback rate means this will finish playing in 5 seconds.\n     */\n    set playbackRate(rate) {\n        if (rate <= 0) {\n            throw new RangeError(\"playbackRate must be greater than 0\");\n        }\n        for (let node of this._sourceNodes) {\n            if (node.constructor.name === \"VideoNode\") {\n                node._globalPlaybackRate = rate;\n                node._playbackRateUpdated = true;\n            }\n        }\n        this._playbackRate = rate;\n    }\n\n    /**\n     *  Return the current playbackRate of the video context.\n     * @return {number} A value representing the playbackRate. 1.0 by default.\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n\n    /**\n     * Set the volume of all VideoNode's created in the VideoContext.\n     * @param {number} volume - the volume to apply to the video nodes.\n     */\n    set volume(vol) {\n        for (let node of this._sourceNodes) {\n            if (node instanceof VideoNode || node instanceof AudioNode) {\n                node.volume = vol;\n            }\n        }\n        this._volume = vol;\n    }\n\n    /**\n     *  Return the current volume of the video context.\n     * @return {number} A value representing the volume. 1.0 by default.\n     */\n    get volume() {\n        return this._volume;\n    }\n\n    /**\n     * Start the VideoContext playing\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement);\n     * var videoNode = ctx.video(\"video.mp4\");\n     * videoNode.connect(ctx.destination);\n     * videoNode.start(0);\n     * videoNode.stop(10);\n     * ctx.play();\n     */\n    play() {\n        console.debug(\"VideoContext - playing\");\n        //Initialise the video elemnt cache\n        if (this._videoElementCache) this._videoElementCache.init();\n        // set the state.\n        this._state = VideoContext.STATE.PLAYING;\n        return true;\n    }\n\n    /**\n     * Pause playback of the VideoContext\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement);\n     * var videoNode = ctx.video(\"video.mp4\");\n     * videoNode.connect(ctx.destination);\n     * videoNode.start(0);\n     * videoNode.stop(20);\n     * ctx.currentTime = 10; // seek 10 seconds in\n     * ctx.play();\n     * setTimeout(function(){ctx.pause();}, 1000); //pause playback after roughly one second.\n     */\n    pause() {\n        console.debug(\"VideoContext - pausing\");\n        this._state = VideoContext.STATE.PAUSED;\n        return true;\n    }\n\n    /**\n     * Create a new node representing a video source\n     *\n     * @param {string|Video} - The URL or video element to create the video from.\n     * @sourceOffset {number} - Offset into the start of the source video to start playing from.\n     * @preloadTime {number} - How many seconds before the video is to be played to start loading it.\n     * @videoElementAttributes {Object} - A dictionary of attributes to map onto the underlying video element.\n     * @return {VideoNode} A new video node.\n     *\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement);\n     * var videoNode = ctx.video(\"video.mp4\");\n     *\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var videoElement = document.getElementById(\"video\");\n     * var ctx = new VideoContext(canvasElement);\n     * var videoNode = ctx.video(videoElement);\n     */\n    video(src, sourceOffset = 0, preloadTime = 4, videoElementAttributes = {}) {\n        let videoNode = new VideoNode(\n            src,\n            this._gl,\n            this._renderGraph,\n            this._currentTime,\n            this._playbackRate,\n            sourceOffset,\n            preloadTime,\n            this._videoElementCache,\n            videoElementAttributes\n        );\n        this._sourceNodes.push(videoNode);\n        return videoNode;\n    }\n\n    audio(src, sourceOffset = 0, preloadTime = 4, audioElementAttributes = {}) {\n        let audioNode = new AudioNode(\n            src,\n            this._gl,\n            this._renderGraph,\n            this._currentTime,\n            this._playbackRate,\n            sourceOffset,\n            preloadTime,\n            this._audioElementCache,\n            audioElementAttributes\n        );\n        this._sourceNodes.push(audioNode);\n        return audioNode;\n    }\n\n    /**\n     * @depricated\n     */\n    createVideoSourceNode(src, sourceOffset = 0, preloadTime = 4, videoElementAttributes = {}) {\n        this._depricate(\n            \"Warning: createVideoSourceNode will be depricated in v1.0, please switch to using VideoContext.video()\"\n        );\n        return this.video(src, sourceOffset, preloadTime, videoElementAttributes);\n    }\n\n    /**\n     * Create a new node representing an image source\n     * @param {string|Image} src - The url or image element to create the image node from.\n     * @param {number} [preloadTime] - How long before a node is to be displayed to attmept to load it.\n     * @param {Object} [imageElementAttributes] - Any attributes to be given to the underlying image element.\n     * @return {ImageNode} A new image node.\n     *\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement);\n     * var imageNode = ctx.image(\"image.png\");\n     *\n     * @example\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var imageElement = document.getElementById(\"image\");\n     * var ctx = new VideoContext(canvasElement);\n     * var imageNode = ctx.image(imageElement);\n     */\n    image(src, preloadTime = 4, imageElementAttributes = {}) {\n        let imageNode = new ImageNode(\n            src,\n            this._gl,\n            this._renderGraph,\n            this._currentTime,\n            preloadTime,\n            imageElementAttributes\n        );\n        this._sourceNodes.push(imageNode);\n        return imageNode;\n    }\n\n    /**\n     * @depricated\n     */\n    createImageSourceNode(src, sourceOffset = 0, preloadTime = 4, imageElementAttributes = {}) {\n        this._depricate(\n            \"Warning: createImageSourceNode will be depricated in v1.0, please switch to using VideoContext.image()\"\n        );\n        return this.image(src, sourceOffset, preloadTime, imageElementAttributes);\n    }\n\n    /**\n     * Create a new node representing a canvas source\n     * @param {Canvas} src - The canvas element to create the canvas node from.\n     * @return {CanvasNode} A new canvas node.\n     */\n    canvas(canvas) {\n        let canvasNode = new CanvasNode(canvas, this._gl, this._renderGraph, this._currentTime);\n        this._sourceNodes.push(canvasNode);\n        return canvasNode;\n    }\n\n    /**\n     * @depricated\n     */\n    createCanvasSourceNode(canvas, sourceOffset = 0, preloadTime = 4) {\n        this._depricate(\n            \"Warning: createCanvasSourceNode will be depricated in v1.0, please switch to using VideoContext.canvas()\"\n        );\n        return this.canvas(canvas, sourceOffset, preloadTime);\n    }\n\n    /**\n     * Create a new effect node.\n     * @param {Object} definition - this is an object defining the shaders, inputs, and properties of the compositing node to create. Builtin definitions can be found by accessing VideoContext.DEFINITIONS.\n     * @return {EffectNode} A new effect node created from the passed definition\n     */\n    effect(definition) {\n        let effectNode = new EffectNode(this._gl, this._renderGraph, definition);\n        this._processingNodes.push(effectNode);\n        return effectNode;\n    }\n\n    /**\n     * @depricated\n     */\n    createEffectNode(definition) {\n        this._depricate(\n            \"Warning: createEffectNode will be depricated in v1.0, please switch to using VideoContext.effect()\"\n        );\n        return this.effect(definition);\n    }\n\n    /**\n     * Create a new compositiing node.\n     *\n     * Compositing nodes are used for operations such as combining multiple video sources into a single track/connection for further processing in the graph.\n     *\n     * A compositing node is slightly different to other processing nodes in that it only has one input in it's definition but can have unlimited connections made to it.\n     * The shader in the definition is run for each input in turn, drawing them to the output buffer. This means there can be no interaction between the spearte inputs to a compositing node, as they are individually processed in seperate shader passes.\n     *\n     * @param {Object} definition - this is an object defining the shaders, inputs, and properties of the compositing node to create. Builtin definitions can be found by accessing VideoContext.DEFINITIONS\n     *\n     * @return {CompositingNode} A new compositing node created from the passed definition.\n     *\n     * @example\n     *\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement);\n     *\n     * //A simple compositing node definition which just renders all the inputs to the output buffer.\n     * var combineDefinition = {\n     *     vertexShader : \"\\\n     *         attribute vec2 a_position;\\\n     *         attribute vec2 a_texCoord;\\\n     *         varying vec2 v_texCoord;\\\n     *         void main() {\\\n     *             gl_Position = vec4(vec2(2.0,2.0)*vec2(1.0, 1.0), 0.0, 1.0);\\\n     *             v_texCoord = a_texCoord;\\\n     *         }\",\n     *     fragmentShader : \"\\\n     *         precision mediump float;\\\n     *         uniform sampler2D u_image;\\\n     *         uniform float a;\\\n     *         varying vec2 v_texCoord;\\\n     *         varying float v_progress;\\\n     *         void main(){\\\n     *             vec4 color = texture2D(u_image, v_texCoord);\\\n     *             gl_FragColor = color;\\\n     *         }\",\n     *     properties:{\n     *         \"a\":{type:\"uniform\", value:0.0},\n     *     },\n     *     inputs:[\"u_image\"]\n     * };\n     * //Create the node, passing in the definition.\n     * var trackNode = videoCtx.compositor(combineDefinition);\n     *\n     * //create two videos which will play at back to back\n     * var videoNode1 = ctx.video(\"video1.mp4\");\n     * videoNode1.play(0);\n     * videoNode1.stop(10);\n     * var videoNode2 = ctx.video(\"video2.mp4\");\n     * videoNode2.play(10);\n     * videoNode2.stop(20);\n     *\n     * //Connect the nodes to the combine node. This will give a single connection representing the two videos which can\n     * //be connected to other effects such as LUTs, chromakeyers, etc.\n     * videoNode1.connect(trackNode);\n     * videoNode2.connect(trackNode);\n     *\n     * //Don't do anything exciting, just connect it to the output.\n     * trackNode.connect(ctx.destination);\n     *\n     */\n    compositor(definition) {\n        let compositingNode = new CompositingNode(this._gl, this._renderGraph, definition);\n        this._processingNodes.push(compositingNode);\n        return compositingNode;\n    }\n\n    /**\n     * @depricated\n     */\n    createCompositingNode(definition) {\n        this._depricate(\n            \"Warning: createCompositingNode will be depricated in v1.0, please switch to using VideoContext.compositor()\"\n        );\n        return this.compositor(definition);\n    }\n\n    /**\n     * Create a new transition node.\n     *\n     * Transistion nodes are a type of effect node which have parameters which can be changed as events on the timeline.\n     *\n     * For example a transition node which cross-fades between two videos could have a \"mix\" property which sets the\n     * progress through the transistion. Rather than having to write your own code to adjust this property at specfic\n     * points in time a transition node has a \"transition\" function which takes a startTime, stopTime, targetValue, and a\n     * propertyName (which will be \"mix\"). This will linearly interpolate the property from the curernt value to\n     * tragetValue between the startTime and stopTime.\n     *\n     * @param {Object} definition - this is an object defining the shaders, inputs, and properties of the transition node to create.\n     * @return {TransitionNode} A new transition node created from the passed definition.\n     * @example\n     *\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement);\n     *\n     * //A simple cross-fade node definition which cross-fades between two videos based on the mix property.\n     * var crossfadeDefinition = {\n     *     vertexShader : \"\\\n     *        attribute vec2 a_position;\\\n     *        attribute vec2 a_texCoord;\\\n     *        varying vec2 v_texCoord;\\\n     *        void main() {\\\n     *            gl_Position = vec4(vec2(2.0,2.0)*a_position-vec2(1.0, 1.0), 0.0, 1.0);\\\n     *            v_texCoord = a_texCoord;\\\n     *         }\",\n     *     fragmentShader : \"\\\n     *         precision mediump float;\\\n     *         uniform sampler2D u_image_a;\\\n     *         uniform sampler2D u_image_b;\\\n     *         uniform float mix;\\\n     *         varying vec2 v_texCoord;\\\n     *         varying float v_mix;\\\n     *         void main(){\\\n     *             vec4 color_a = texture2D(u_image_a, v_texCoord);\\\n     *             vec4 color_b = texture2D(u_image_b, v_texCoord);\\\n     *             color_a[0] *= mix;\\\n     *             color_a[1] *= mix;\\\n     *             color_a[2] *= mix;\\\n     *             color_a[3] *= mix;\\\n     *             color_b[0] *= (1.0 - mix);\\\n     *             color_b[1] *= (1.0 - mix);\\\n     *             color_b[2] *= (1.0 - mix);\\\n     *             color_b[3] *= (1.0 - mix);\\\n     *             gl_FragColor = color_a + color_b;\\\n     *         }\",\n     *     properties:{\n     *         \"mix\":{type:\"uniform\", value:0.0},\n     *     },\n     *     inputs:[\"u_image_a\",\"u_image_b\"]\n     * };\n     *\n     * //Create the node, passing in the definition.\n     * var transitionNode = videoCtx.transition(crossfadeDefinition);\n     *\n     * //create two videos which will overlap by two seconds\n     * var videoNode1 = ctx.video(\"video1.mp4\");\n     * videoNode1.play(0);\n     * videoNode1.stop(10);\n     * var videoNode2 = ctx.video(\"video2.mp4\");\n     * videoNode2.play(8);\n     * videoNode2.stop(18);\n     *\n     * //Connect the nodes to the transistion node.\n     * videoNode1.connect(transitionNode);\n     * videoNode2.connect(transitionNode);\n     *\n     * //Set-up a transition which happens at the crossover point of the playback of the two videos\n     * transitionNode.transition(8,10,1.0,\"mix\");\n     *\n     * //Connect the transition node to the output\n     * transitionNode.connect(ctx.destination);\n     *\n     * //start playback\n     * ctx.play();\n     */\n    transition(definition) {\n        let transitionNode = new TransitionNode(this._gl, this._renderGraph, definition);\n        this._processingNodes.push(transitionNode);\n        return transitionNode;\n    }\n\n    /**\n     * @depricated\n     */\n    createTransitionNode(definition) {\n        this._depricate(\n            \"Warning: createTransitionNode will be depricated in v1.0, please switch to using VideoContext.transition()\"\n        );\n        return this.transition(definition);\n    }\n\n    _isStalled() {\n        for (let i = 0; i < this._sourceNodes.length; i++) {\n            let sourceNode = this._sourceNodes[i];\n            if (!sourceNode._isReady()) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    /**\n     * This allows manual calling of the update loop of the videoContext.\n     *\n     * @param {Number} dt - The difference in seconds between this and the previous calling of update.\n     * @example\n     *\n     * var canvasElement = document.getElementById(\"canvas\");\n     * var ctx = new VideoContext(canvasElement, undefined, {\"manualUpdate\" : true});\n     *\n     * var previousTime;\n     * function update(time){\n     *     if (previousTime === undefined) previousTime = time;\n     *     var dt = (time - previousTime)/1000;\n     *     ctx.update(dt);\n     *     previousTime = time;\n     *     requestAnimationFrame(update);\n     * }\n     * update();\n     *\n     */\n    update(dt) {\n        this._update(dt);\n    }\n\n    _update(dt) {\n        //Remove any destroyed nodes\n        this._sourceNodes = this._sourceNodes.filter(sourceNode => {\n            if (!sourceNode.destroyed) return sourceNode;\n        });\n\n        this._processingNodes = this._processingNodes.filter(processingNode => {\n            if (!processingNode.destroyed) return processingNode;\n        });\n\n        if (\n            this._state === VideoContext.STATE.PLAYING ||\n            this._state === VideoContext.STATE.STALLED ||\n            this._state === VideoContext.STATE.PAUSED\n        ) {\n            this._callCallbacks(\"update\");\n\n            if (this._state !== VideoContext.STATE.PAUSED) {\n                if (this._isStalled()) {\n                    this._callCallbacks(\"stalled\");\n                    this._state = VideoContext.STATE.STALLED;\n                } else {\n                    this._state = VideoContext.STATE.PLAYING;\n                }\n            }\n\n            if (this._state === VideoContext.STATE.PLAYING) {\n                //Handle timeline callbacks.\n                let activeCallbacks = new Map();\n                for (let callback of this._timelineCallbacks) {\n                    if (\n                        callback.time >= this.currentTime &&\n                        callback.time < this._currentTime + dt * this._playbackRate\n                    ) {\n                        //group the callbacks by time\n                        if (!activeCallbacks.has(callback.time))\n                            activeCallbacks.set(callback.time, []);\n                        activeCallbacks.get(callback.time).push(callback);\n                    }\n                }\n\n                //Sort the groups of callbacks by the times of the groups\n                let timeIntervals = Array.from(activeCallbacks.keys());\n                timeIntervals.sort(function(a, b) {\n                    return a - b;\n                });\n\n                for (let t of timeIntervals) {\n                    let callbacks = activeCallbacks.get(t);\n                    callbacks.sort(function(a, b) {\n                        return a.ordering - b.ordering;\n                    });\n                    for (let callback of callbacks) {\n                        callback.func();\n                    }\n                }\n\n                this._currentTime += dt * this._playbackRate;\n                if (this._currentTime > this.duration && this._endOnLastSourceEnd) {\n                    //Do an update od the sourcenodes in case anything in the \"ended\" callbacks modifes currentTime and sources haven't had a chance to stop.\n                    for (let i = 0; i < this._sourceNodes.length; i++) {\n                        this._sourceNodes[i]._update(this._currentTime);\n                    }\n                    this._state = VideoContext.STATE.ENDED;\n                    this._callCallbacks(\"ended\");\n                }\n            }\n\n            let sourcesPlaying = false;\n\n            for (let i = 0; i < this._sourceNodes.length; i++) {\n                let sourceNode = this._sourceNodes[i];\n\n                if (this._state === VideoContext.STATE.STALLED) {\n                    if (sourceNode._isReady() && sourceNode._state === SOURCENODESTATE.playing)\n                        sourceNode._pause();\n                }\n                if (this._state === VideoContext.STATE.PAUSED) {\n                    sourceNode._pause();\n                }\n                if (this._state === VideoContext.STATE.PLAYING) {\n                    sourceNode._play();\n                }\n                sourceNode._update(this._currentTime);\n                if (\n                    sourceNode._state === SOURCENODESTATE.paused ||\n                    sourceNode._state === SOURCENODESTATE.playing\n                ) {\n                    sourcesPlaying = true;\n                }\n            }\n\n            if (\n                sourcesPlaying !== this._sourcesPlaying &&\n                this._state === VideoContext.STATE.PLAYING\n            ) {\n                if (sourcesPlaying === true) {\n                    this._callCallbacks(\"content\");\n                } else {\n                    this._callCallbacks(\"nocontent\");\n                }\n                this._sourcesPlaying = sourcesPlaying;\n            }\n\n            /*\n            * Itterate the directed acyclic graph using Khan's algorithm (KHAAAAAN!).\n            *\n            * This has highlighted a bunch of ineffencies in the rendergraph class about how its stores connections.\n            * Mainly the fact that to get inputs for a node you have to iterate the full list of connections rather than\n            * a node owning it's connections.\n            * The trade off with changing this is making/removing connections becomes more costly performance wise, but\n            * this is deffinately worth while because getting the connnections is a much more common operation.\n            *\n            * TL;DR Future matt - refactor this.\n            *\n            */\n            let sortedNodes = [];\n            let connections = this._renderGraph.connections.slice();\n            let nodes = RenderGraph.getInputlessNodes(connections);\n\n            while (nodes.length > 0) {\n                let node = nodes.pop();\n                sortedNodes.push(node);\n                for (let edge of RenderGraph.outputEdgesFor(node, connections)) {\n                    let index = connections.indexOf(edge);\n                    if (index > -1) connections.splice(index, 1);\n                    if (RenderGraph.inputEdgesFor(edge.destination, connections).length === 0) {\n                        nodes.push(edge.destination);\n                    }\n                }\n            }\n\n            for (let node of sortedNodes) {\n                if (this._sourceNodes.indexOf(node) === -1) {\n                    node._update(this._currentTime);\n                    node._render();\n                }\n            }\n        }\n    }\n\n    /**\n     * Destroy all nodes in the graph and reset the timeline. After calling this any created nodes will be unusable.\n     */\n    reset() {\n        for (let callback of this._callbacks) {\n            this.unregisterCallback(callback);\n        }\n        for (let node of this._sourceNodes) {\n            node.destroy();\n        }\n        for (let node of this._processingNodes) {\n            node.destroy();\n        }\n        this._update(0);\n        this._sourceNodes = [];\n        this._processingNodes = [];\n        this._timeline = [];\n        this._currentTime = 0;\n        this._state = VideoContext.STATE.PAUSED;\n        this._playbackRate = 1.0;\n        this._sourcesPlaying = undefined;\n        this._callbacks.set(\"stalled\", []);\n        this._callbacks.set(\"update\", []);\n        this._callbacks.set(\"ended\", []);\n        this._callbacks.set(\"content\", []);\n        this._callbacks.set(\"nocontent\", []);\n        this._timelineCallbacks = [];\n    }\n\n    _depricate(msg) {\n        console.log(msg);\n    }\n\n    static get DEFINITIONS() {\n        return DEFINITIONS;\n    }\n\n    /**\n     * Get a JS Object containing the state of the VideoContext instance and all the created nodes.\n     */\n    snapshot() {\n        return snapshot(this);\n    }\n}\n\n//playing - all sources are active\n//paused - all sources are paused\n//stalled - one or more sources is unable to play\n//ended - all sources have finished playing\n//broken - the render graph is in a broken state\nVideoContext.STATE = {};\nVideoContext.STATE.PLAYING = 0;\nVideoContext.STATE.PAUSED = 1;\nVideoContext.STATE.STALLED = 2;\nVideoContext.STATE.ENDED = 3;\nVideoContext.STATE.BROKEN = 4;\n\nVideoContext.visualiseVideoContextTimeline = visualiseVideoContextTimeline;\nVideoContext.visualiseVideoContextGraph = visualiseVideoContextGraph;\nVideoContext.createControlFormForNode = createControlFormForNode;\nVideoContext.createSigmaGraphDataFromRenderGraph = createSigmaGraphDataFromRenderGraph;\nVideoContext.exportToJSON = exportToJSON;\nVideoContext.updateablesManager = updateablesManager;\nVideoContext.importSimpleEDL = importSimpleEDL;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/videocontext.js\n// module id = 0\n// module chunks = 0"],"sourceRoot":""}